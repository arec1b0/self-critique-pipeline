{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Integration Patterns\n",
        "\n",
        "This notebook demonstrates various patterns for integrating the Self-Critique pipeline into larger, real-world systems, covering asynchronous processing, data persistence, and CI/CD workflows.\n",
        "\n",
        "## Learning Objectives\n",
        "\n",
        "- **Asynchronous Workflows**: Use a task queue like Celery to handle long-running pipeline executions without blocking.\n",
        "- **Data Persistence**: Store pipeline results in a PostgreSQL database.\n",
        "- **CI/CD Integration**: Automate testing and quality checks using GitHub Actions.\n",
        "- **Prompt Versioning**: Manage prompt templates with DVC.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 1: Async Pipeline Integration (Celery)\n",
        "\n",
        "For long-running tasks, it's best to use a task queue to process them in the background. This allows the API to return a response immediately.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from celery import Celery\n",
        "import time\n",
        "\n",
        "# Configure Celery\n",
        "# In a real app, this would be in a separate config file.\n",
        "# Requires a message broker like RabbitMQ or Redis.\n",
        "celery_app = Celery('tasks', broker='redis://localhost:6379/0', backend='redis://localhost:6379/0')\n",
        "\n",
        "@celery_app.task\n",
        "def run_pipeline_async(paper_text: str):\n",
        "    \"\"\"Celery task to run the pipeline asynchronously.\"\"\"\n",
        "    print(f\"Starting pipeline for paper: {paper_text[:50]}...\")\n",
        "    # Simulate a long-running process\n",
        "    time.sleep(10)\n",
        "    result = {\"summary\": \"This is the final summary.\", \"status\": \"SUCCESS\"}\n",
        "    print(\"Pipeline finished.\")\n",
        "    return result\n",
        "\n",
        "# Example of how to call the task from an API endpoint\n",
        "def start_pipeline_job(paper_text: str):\n",
        "    task = run_pipeline_async.delay(paper_text)\n",
        "    return {\"task_id\": task.id, \"status\": \"PENDING\"}\n",
        "\n",
        "print(\"✓ Celery task defined. To run a worker: celery -A your_module.celery_app worker -l info\")\n",
        "\n",
        "# Example usage:\n",
        "# job = start_pipeline_job(\"Attention is all you need...\")\n",
        "# print(job)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 2: Database Integration (PostgreSQL)\n",
        "\n",
        "Storing results in a database allows for historical analysis, caching, and querying.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sqlalchemy\n",
        "from sqlalchemy import create_engine, Column, Integer, String, Text, MetaData, Table\n",
        "from sqlalchemy.orm import sessionmaker\n",
        "import json\n",
        "\n",
        "# Database connection (use a real connection string in production)\n",
        "DATABASE_URL = \"sqlite:///./test.db\" # Using SQLite for demonstration\n",
        "engine = create_engine(DATABASE_URL)\n",
        "metadata = MetaData()\n",
        "\n",
        "# Define the results table\n",
        "pipeline_results = Table('pipeline_results',\n",
        "    metadata,\n",
        "    Column('id', Integer, primary_key=True),\n",
        "    Column('paper_text_hash', String(64), unique=True),\n",
        "    Column('summary', Text),\n",
        "    Column('critique', Text),\n",
        "    Column('final_summary', Text),\n",
        "    Column('metrics', Text) # Storing metrics as a JSON string\n",
        ")\n",
        "\n",
        "metadata.create_all(engine)\n",
        "\n",
        "SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)\n",
        "\n",
        "def save_results(db_session, result_data: dict):\n",
        "    \"\"\"Saves pipeline results to the database.\"\"\"\n",
        "    import hashlib\n",
        "    \n",
        "    paper_hash = hashlib.sha256(result_data['paper_text'].encode()).hexdigest()\n",
        "    \n",
        "    insert_stmt = pipeline_results.insert().values(\n",
        "        paper_text_hash=paper_hash,\n",
        "        summary=result_data['summary'],\n",
        "        critique=result_data['critique'],\n",
        "        final_summary=result_data['final_summary'],\n",
        "        metrics=json.dumps(result_data['metrics'])\n",
        "    )\n",
        "    db_session.execute(insert_stmt)\n",
        "    db_session.commit()\n",
        "    print(f\"✓ Results saved to database with hash: {paper_hash}\")\n",
        "\n",
        "# Example usage\n",
        "db = SessionLocal()\n",
        "sample_result = {\n",
        "    'paper_text': 'This is the paper text.',\n",
        "    'summary': 'Initial summary.',\n",
        "    'critique': 'A critique.',\n",
        "    'final_summary': 'The final, revised summary.',\n",
        "    'metrics': {'tokens': 500, 'latency': 5.2}\n",
        "}\n",
        "save_results(db, sample_result)\n",
        "db.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 3: CI/CD Pipeline Integration (GitHub Actions)\n",
        "\n",
        "A CI/CD pipeline automates testing and deployment, ensuring code quality and consistency.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "bash"
        ]
      },
      "outputs": [],
      "source": [
        "%%writefile ../../.github/workflows/ci.yaml\n",
        "name: CI Pipeline\n",
        "\n",
        "on:\n",
        "  push:\n",
        "    branches: [ main ]\n",
        "  pull_request:\n",
        "    branches: [ main ]\n",
        "\n",
        "jobs:\n",
        "  test:\n",
        "    runs-on: ubuntu-latest\n",
        "    steps:\n",
        "    - uses: actions/checkout@v3\n",
        "    \n",
        "    - name: Set up Python\n",
        "      uses: actions/setup-python@v3\n",
        "      with:\n",
        "        python-version: '3.9'\n",
        "    \n",
        "    - name: Install dependencies\n",
        "      run: |\n",
        "        pip install -r requirements.txt\n",
        "        pip install -r requirements-dev.txt\n",
        "        \n",
        "    - name: Lint with flake8\n",
        "      run: |\n",
        "        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics\n",
        "        \n",
        "    - name: Run unit tests\n",
        "      run: |\n",
        "        pytest\n",
        "        \n",
        "  quality-gate:\n",
        "    runs-on: ubuntu-latest\n",
        "    needs: test\n",
        "    steps:\n",
        "    - uses: actions/checkout@v3\n",
        "    # ... (steps to run model_evaluation_qa.ipynb and check quality gate)\n",
        "    - name: Run Quality Gate\n",
        "      run: echo \"Simulating quality gate check... PASSED\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 4: DVC Integration for Prompt Versioning\n",
        "\n",
        "Using DVC (Data Version Control) allows us to version our prompt templates alongside our code, ensuring reproducibility.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "bash"
        ]
      },
      "outputs": [],
      "source": [
        "# 1. Initialize DVC (do this once in your repo)\n",
        "# dvc init\n",
        "\n",
        "# 2. Create a directory for prompts\n",
        "mkdir -p ../../prompts\n",
        "echo \"Summarize this paper: {{paper_text}}\" > ../../prompts/summary_v1.txt\n",
        "\n",
        "# 3. Add the prompts directory to DVC tracking\n",
        "# dvc add prompts\n",
        "\n",
        "# 4. Commit to Git\n",
        "# git add prompts.dvc .gitignore\n",
        "# git commit -m \"feat: Add initial prompt templates with DVC\"\n",
        "\n",
        "print(\"✓ DVC setup for prompts complete. Use `dvc add prompts` after each change.\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
