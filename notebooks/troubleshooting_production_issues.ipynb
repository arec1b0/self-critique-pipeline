{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Troubleshooting Production Issues\n",
        "\n",
        "This notebook serves as an operational runbook for diagnosing and resolving common issues in the production Self-Critique pipeline. It provides code examples and strategies for handling errors, timeouts, and performance degradation.\n",
        "\n",
        "## Learning Objectives\n",
        "\n",
        "- **Error Handling**: Implement robust error handling for API calls and data parsing.\n",
        "- **Retry Strategies**: Use exponential backoff to handle transient issues like rate limiting.\n",
        "- **Failure Classification**: Categorize errors to understand root causes.\n",
        "- **Debugging Techniques**: Learn how to diagnose issues using logs and metrics.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 1: Common Failure Modes & Recovery\n",
        "\n",
        "| Failure Mode | Cause | Recovery Strategy |\n",
        "| :--- | :--- | :--- |\n",
        "| API Rate Limiting | Exceeding allowed requests/minute | Implement exponential backoff and retry. |\n",
        "| API 5xx Errors | Server-side issues at the provider | Retry with backoff; have a fallback model if possible. |\n",
        "| XML Parsing Failure | Malformed XML in LLM response | Add a retry loop that asks the model to fix the XML. |\n",
        "| Token Limit Exceeded | Input text is too long | Truncate input or use a model with a larger context window. |\n",
        "| Request Timeout | Network latency or slow model response | Increase client timeout; implement async processing. |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 2: Rate Limiting & Retry Strategies (Exponential Backoff)\n",
        "\n",
        "When an API fails due to a transient issue, it's best to retry with an increasing delay.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "import random\n",
        "import httpx\n",
        "\n",
        "def call_api_with_retry(url: str, max_retries: int = 5, initial_delay: int = 1):\n",
        "    \"\"\"Calls an API with exponential backoff and jitter.\"\"\"\n",
        "    delay = initial_delay\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            print(f\"Attempt {attempt + 1}/{max_retries}...\")\n",
        "            # Simulate an API call that might fail\n",
        "            if random.random() < 0.8: # 80% chance of failure\n",
        "                raise httpx.ReadTimeout(\"Request timed out\")\n",
        "            \n",
        "            response = {\"status\": 200, \"data\": \"Success!\"}\n",
        "            print(\"API call successful.\")\n",
        "            return response\n",
        "        \n",
        "        except httpx.ReadTimeout as e:\n",
        "            print(f\"Error: {e}. Retrying in {delay:.2f} seconds...\")\n",
        "            time.sleep(delay)\n",
        "            delay *= 2  # Double the delay\n",
        "            delay += random.uniform(0, 1) # Add jitter\n",
        "            \n",
        "    raise Exception(f\"API call failed after {max_retries} attempts.\")\n",
        "\n",
        "# Example usage\n",
        "try:\n",
        "    result = call_api_with_retry(\"http://example.com/api\")\n",
        "except Exception as e:\n",
        "    print(e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 3: Handling XML Parsing Failures\n",
        "\n",
        "Sometimes, the LLM may return malformed XML. We can create a recovery loop that sends the faulty XML back to the model and asks it to correct it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "def parse_xml_with_recovery(llm_output: str, max_retries: int = 2) -> ET.Element:\n",
        "    \"\"\"Tries to parse XML, and on failure, asks the LLM to fix it.\"\"\"\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            return ET.fromstring(llm_output)\n",
        "        except ET.ParseError as e:\n",
        "            print(f\"XML parsing failed: {e}. Attempting recovery...\")\n",
        "            # In a real app, this would be an LLM call\n",
        "            llm_output = f\"<root><fixed>{llm_output.replace('<', '')}</fixed></root>\" # Simulate fixing\n",
        "            print(\"Simulated LLM call to fix XML.\")\n",
        "            \n",
        "    raise ValueError(f\"Failed to parse XML after {max_retries} recovery attempts.\")\n",
        "\n",
        "malformed_xml = \"<root><item>One</item><item>Two</malformed></root>\"\n",
        "try:\n",
        "    parsed = parse_xml_with_recovery(malformed_xml)\n",
        "    print(\"Successfully parsed XML after recovery.\")\n",
        "except ValueError as e:\n",
        "    print(e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 4: Diagnosing Quality Degradation\n",
        "\n",
        "When quality scores drop, use the following checklist to diagnose the cause:\n",
        "\n",
        "1.  **Check for Data Drift**: Has the input data changed? Use the `advanced_monitoring_drift_detection.ipynb` notebook to compare the distribution of recent inputs against a baseline.\n",
        "    - **Query**: `SELECT AVG(paper_length) FROM logs WHERE time > now() - '1d'`\n",
        "\n",
        "2.  **Review Failing Examples**: Look at specific inputs that are receiving low quality scores. Is there a pattern?\n",
        "    - **Query**: `SELECT paper_text, final_summary, critique FROM pipeline_results WHERE overall_quality < 7 ORDER BY timestamp DESC LIMIT 10`\n",
        "\n",
        "3.  **Check for Prompt Injection**: Have users started submitting inputs designed to subvert the prompts?\n",
        "\n",
        "4.  **A/B Test a Fix**: Once you have a hypothesis (e.g., \"the prompt doesn't handle bullet points well\"), create a new prompt version and test it against the old one using the `model_evaluation_qa.ipynb` notebook.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 5: Performance Anomaly Root Cause Analysis\n",
        "\n",
        "When latency spikes or throughput drops, use this checklist:\n",
        "\n",
        "1.  **Check External API Status**: Is the LLM provider (e.g., Anthropic) reporting an incident? Check their status page.\n",
        "\n",
        "2.  **Analyze Latency by Stage**: Use distributed tracing (OpenTelemetry) to see which stage of the pipeline is causing the slowdown.\n",
        "\n",
        "3.  **Check for Large Inputs/Outputs**: Are you processing unusually large papers or generating very long summaries? Correlate latency with token counts.\n",
        "    - **Prometheus Query**: `rate(http_request_duration_seconds_sum[5m]) / rate(http_request_duration_seconds_count[5m])`\n",
        "\n",
        "4.  **Check Infrastructure Resources**: Are your pods CPU or memory-throttled? Check your Kubernetes dashboard for resource utilization.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
