{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Advanced Monitoring & Observability\n",
        "\n",
        "This notebook provides a guide to integrating the Self-Critique pipeline with a production monitoring stack, focusing on Prometheus, Grafana, and OpenTelemetry for deep system insights.\n",
        "\n",
        "## Learning Objectives\n",
        "\n",
        "- **Metrics Export**: Expose custom application metrics for Prometheus scraping.\n",
        "- **Structured Logging**: Implement JSON-formatted logs for easier parsing and querying.\n",
        "- **Distributed Tracing**: Use OpenTelemetry to trace requests across the pipeline stages.\n",
        "- **Dashboarding**: Learn how to visualize key metrics in Grafana.\n",
        "- **Alerting**: Define alert rules for proactive issue detection.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 1: Structured Logging\n",
        "\n",
        "Structured logs (e.g., in JSON format) are machine-readable and allow for powerful querying in log aggregation systems like Elasticsearch or Loki.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import logging\n",
        "import json\n",
        "from pythonjsonlogger import jsonlogger\n",
        "\n",
        "# Get a logger\n",
        "logger = logging.getLogger(__name__)\n",
        "logger.setLevel(logging.INFO)\n",
        "\n",
        "# Add a JSON formatter\n",
        "logHandler = logging.StreamHandler()\n",
        "formatter = jsonlogger.JsonFormatter('%(asctime)s %(name)s %(levelname)s %(message)s')\n",
        "logHandler.setFormatter(formatter)\n",
        "logger.addHandler(logHandler)\n",
        "\n",
        "# Example log\n",
        "logger.info(\"Pipeline execution started\", extra={\n",
        "    'request_id': 'xyz-123',\n",
        "    'model': 'claude-sonnet-4-20250514',\n",
        "    'paper_length': 4500\n",
        "})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 2: Prometheus Metrics Export\n",
        "\n",
        "We'll use the `prometheus-fastapi-instrumentator` library to automatically expose standard metrics and add our own custom ones.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from fastapi import FastAPI\n",
        "from prometheus_fastapi_instrumentator import Instrumentator\n",
        "from prometheus_client import Counter\n",
        "\n",
        "# This would be in your main api.py file\n",
        "app = FastAPI()\n",
        "\n",
        "# Add custom metrics\n",
        "pipeline_runs_total = Counter(\n",
        "    \"pipeline_runs_total\", \n",
        "    \"Total number of pipeline runs\",\n",
        "    ['model_name']\n",
        ")\n",
        "xml_parsing_errors = Counter(\n",
        "    \"xml_parsing_errors_total\",\n",
        "    \"Total number of XML parsing errors\"\n",
        ")\n",
        "\n",
        "@app.get(\"/\")\n",
        "def read_root():\n",
        "    # Increment custom metric\n",
        "    pipeline_runs_total.labels(model_name='claude-sonnet-4-20250514').inc()\n",
        "    return {\"Hello\": \"World\"}\n",
        "\n",
        "# Instrument the app\n",
        "Instrumentator().instrument(app).expose(app, endpoint=\"/metrics\")\n",
        "\n",
        "print(\"âœ“ FastAPI app instrumented. Metrics available at /metrics\")\n",
        "# To run this: uvicorn your_module:app\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 3: OpenTelemetry Instrumentation (Tracing)\n",
        "\n",
        "Distributed tracing allows us to follow a single request as it passes through different stages of our pipeline, helping us pinpoint latency issues.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from opentelemetry import trace\n",
        "from opentelemetry.sdk.trace import TracerProvider\n",
        "from opentelemetry.sdk.trace.export import ConsoleSpanExporter, SimpleSpanProcessor\n",
        "\n",
        "# Set up the tracer provider\n",
        "trace.set_tracer_provider(TracerProvider())\n",
        "tracer = trace.get_tracer(__name__)\n",
        "\n",
        "# Export traces to the console for demonstration\n",
        "# In production, you'd use an exporter for Jaeger, Zipkin, or another backend\n",
        "trace.get_tracer_provider().add_span_processor(\n",
        "    SimpleSpanProcessor(ConsoleSpanExporter())\n",
        ")\n",
        "\n",
        "def run_pipeline_stage(stage_name: str, paper_text: str):\n",
        "    with tracer.start_as_current_span(f\"pipeline.{stage_name}\") as span:\n",
        "        span.set_attribute(\"paper.length\", len(paper_text))\n",
        "        print(f\"Executing stage: {stage_name}\")\n",
        "        # Simulate work\n",
        "        import time\n",
        "        time.sleep(0.5)\n",
        "        span.set_attribute(\"output.tokens\", 512)\n",
        "        print(f\"Stage {stage_name} complete.\")\n",
        "\n",
        "# Trace a full pipeline execution\n",
        "with tracer.start_as_current_span(\"pipeline.run\") as parent_span:\n",
        "    paper = \"Attention is all you need...\"\n",
        "    parent_span.set_attribute(\"model\", \"claude-sonnet-4-20250514\")\n",
        "    \n",
        "    run_pipeline_stage(\"summary\", paper)\n",
        "    run_pipeline_stage(\"critique\", paper)\n",
        "    run_pipeline_stage(\"revision\", paper)\n",
        "    \n",
        "    print(\"Pipeline execution traced.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 4: Grafana Dashboard Definitions\n",
        "\n",
        "Grafana dashboards are defined as JSON. Below is a conceptual example of a panel for a Grafana dashboard that visualizes P99 latency.\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"title\": \"P99 Latency (ms)\",\n",
        "  \"type\": \"timeseries\",\n",
        "  \"targets\": [\n",
        "    {\n",
        "      \"expr\": \"histogram_quantile(0.99, sum(rate(http_request_duration_seconds_bucket[5m])) by (le))\",\n",
        "      \"legendFormat\": \"P99 Latency\"\n",
        "    }\n",
        "  ],\n",
        "  \"gridPos\": { \"h\": 8, \"w\": 12, \"x\": 0, \"y\": 0 }\n",
        "}\n",
        "```\n",
        "\n",
        "**Key Metrics for Dashboarding:**\n",
        "\n",
        "- **Latency**: P50, P95, P99 request latency.\n",
        "- **Throughput**: Requests per second (RPS).\n",
        "- **Error Rate**: Percentage of 5xx server errors.\n",
        "- **Token Counts**: Input and output tokens per model.\n",
        "- **Quality Scores**: Average `overall_quality` score over time.\n",
        "- **Cost**: Estimated cost based on token counts.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 5: Alert Rule Definitions\n",
        "\n",
        "Alerts are defined in Prometheus using a YAML file. Here's an example of an alert that fires when the API's error rate is too high.\n",
        "\n",
        "```yaml\n",
        "groups:\n",
        "- name: api_alerts\n",
        "  rules:\n",
        "  - alert: HighErrorRate\n",
        "    expr: (sum(rate(http_requests_total{status=~\"5..\"}[5m])) / sum(rate(http_requests_total[5m]))) > 0.05\n",
        "    for: 10m\n",
        "    labels:\n",
        "      severity: page\n",
        "    annotations:\n",
        "      summary: \"High API Error Rate\"\n",
        "      description: \"The API is returning 5xx errors for more than 5% of requests over the last 10 minutes.\"\n",
        "```\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
